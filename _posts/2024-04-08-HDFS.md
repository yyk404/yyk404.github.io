---
layout: post
title: HDFS
tags: [HDFS]
categories: Demo
excerpt_separator: <!--more-->
---

HDFS
<!--more-->

## HDFS

### 常用命令

```shell
\# HDFS Shell命令示例 
hdfs dfs -mkdir /data 
hdfs dfs -put local_file /data/ 
hdfs dfs -ls /data/ 
hdfs dfs -get /data/local_file local_copy
```

如果集群是高 HA 集群（双 namenode），您可以通过如下命名查看哪个 namenode 是 active 的。

```shell
#nn1 是 namenode 的 ID，一般为 nn1 和 nn2
hdfs haadmin -getServiceState nn1
#查看当前集群报告
hdfs dfsadmin -report
#namenode 离开安全模式
hdfs dfsadmin -safemode leave
```

### 体系架构

**HDFS采用master/slave架构。**一个HDFS集群是由一个Namenode和一定数目的Datanodes组成。Namenode是一个中心服务器，负责管理文件系统的名字空间(namespace)以及客户端对文件的访问。集群中的Datanode一般是一个节点一个，负责管理它所在节点上的存储。

HDFS暴露了文件系统的名字空间，用户能够以文件的形式在上面存储数据。从内部看，一个文件其实被分成一个或多个数据块，这些块存储在一组Datanode上。

- Namenode执行文件系统的名字空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体Datanode节点的映射。 Namenode全权管理数据块的复制，它周期性地从集群中的每个Datanode接收心跳信号和块状态报告(Blockreport)。接收到心跳信号意味着该Datanode节点工作正常。块状态报告包含了一个该Datanode上所有数据块的列表。NameNode：负责管理分布式文件系统的命名空间（NameSpace），保存了两个核心的数据结构，即FsImage和EditLog。
  - **FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据**
  - **EditLog操作日志文件记录了所有针对文件的创建、删除、重命名等操作**
- Datanode负责处理文件系统客户端的读写请求。在Namenode的统一调度下进行数据块的创建、删除和复制。

#### SecondaryNameNode节点

简单的说，SecondaryNameNode节点的主要功能是周期性将元数据节点的命名空间镜像文件和修改日志进行合并，以防日志文件过大。

> SecondaryNameNode光从字面上理解，很容易让人认为是NameNode的热备进程。其实不是，SecondaryNameNode是HDFS架构中的一个组成部分。它并不是元数据节点出现问题时的备用节点，它和元数据节点负责不同的事情。

### HDFS数据存放规则

- 第一个副本：放置在**上传文件的数据节点**；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点
- 第二个副本：放置在与第一个副本**不同的机架的节点**上
- 第三个副本：与第一个副本**相同机架的其他节点**上
- 更多副本：随机节点

### HDFS读写数据

#### 写数据

1. 跟NameNode通信请求上传文件，NameNode检查目标文件是否已经存在，父目录是否已经存在
2. NameNode返回是否可以上传
3. Client先对文件进行切分，请求第一个block该传输到哪些DataNode服务器上
4. NameNode返回3个DataNode服务器DataNode 1，DataNode 2，DataNode 3
5. Client请求3台中的一台DataNode 1(网络拓扑上的就近原则，如果都一样，则随机挑选一台DataNode)上传数据（本质上是一个RPC调用，建立pipeline）,DataNode 1收到请求会继续调用DataNode 2,然后DataNode 2调用DataNode 3，将整个pipeline建立完成，然后逐级返回客户端
6. Client开始往DataNode 1上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位。写入的时候DataNode会进行数据校验，它并不是通过一个packet进行一次校验而是以chunk为单位进行校验（512byte）。DataNode 1收到一个packet就会传给DataNode 2，DataNode 2传给DataNode 3，DataNode 1每传一个packet会放入一个应答队列等待应答
7. 当一个block传输完成之后，Client再次请求NameNode上传第二个block的服务器.

#### 读数据

1. 与NameNode通信查询元数据，找到文件块所在的DataNode服务器 　

2. 挑选一台DataNode（网络拓扑上的就近原则，如果都一样，则随机挑选一台DataNode）服务器，请求建立socket流 　

3.  DataNode开始发送数据(从磁盘里面读取数据放入流，以packet（一个packet为64kb）为单位来做校验) 　

4. 客户端以packet为单位接收，先在本地缓存，然后写入目标文件

> 为了降低整体的带宽消耗和读取延时，HDFS会尽量让读取程序读取离它最近的副本。如果在读取程序的同一个机架上有一个副本，那么就读取该副本。如果一个HDFS集群跨越多个数据中心，那么客户端也将首先读本地数据中心的副本。

### 架构稳定

#### 心跳机制和重新复制

**每个 DataNode 定期向 NameNode 发送心跳消息**，如果超过指定时间没有收到心跳消息，则将 DataNode 标记为死亡。NameNode 不会将任何新的 IO 请求转发给标记为死亡的 DataNode，也不会再使用这些 DataNode 上的数据。 由于数据不再可用，可能会导致某些块的复制因子小于其指定值，NameNode 会跟踪这些块，并在必要的时候进行重新复制。

#### 数据的完整性

由于存储设备故障等原因，存储在 DataNode 上的数据块也会发生损坏。**为了避免读取到已经损坏的数据而导致错误，HDFS 提供了数据完整性校验机制来保证数据的完整性**，具体操作如下：

当客户端创建 HDFS 文件时，它会计算文件的每个块的 `校验和`，并将 `校验和` 存储在同一 HDFS 命名空间下的单独的隐藏文件中。当客户端检索文件内容时，它会验证从每个 DataNode 接收的数据是否与存储在关联校验和文件中的 `校验和` 匹配。如果匹配失败，则证明数据已经损坏，此时客户端会选择从其他 DataNode 获取该块的其他可用副本。

#### 元数据的磁盘故障

`FsImage` 和 `EditLog` 是 HDFS 的核心数据，这些数据的意外丢失可能会导致整个 HDFS 服务不可用。为了避免这个问题，可以配置 NameNode 使其支持 `FsImage` 和 `EditLog` 多副本同步，这样 `FsImage` 或 `EditLog` 的任何改变都会引起每个副本 `FsImage` 和 `EditLog` 的同步更新。

#### 支持快照

快照支持在特定时刻存储数据副本，在数据意外损坏时，可以通过回滚操作恢复到健康的数据状态。

### HDFS故障类型和其检测方法

#### 数据节点出错

每个DataNode会定期向名称节点发送"心跳"信息，向NameNode报告自己的状态。当某个DataNode出错，NameNode不会再给它们发送任何I/O请求。

由于有DataNode出错，意味着某些数据的副本数量将小于冗余因子（默认是3），就会启动数据冗余复制，为缺失副本的数据生成新的副本。

#### NameNode出错

NameNode出错，还有SecondaryNameNode提供的备份。